#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Veri Ãœretim ModÃ¼lÃ¼

Bu modÃ¼l, gerÃ§ekÃ§i akÄ±llÄ± sayaÃ§ yÃ¼k verileri Ã¼retir.
"""

import time
import numpy as np
import pandas as pd
from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType

from utils.logger import get_logger
from utils.config import DATA_CONFIG

# Veri Ã¼retim parametreleri (config.py'a eklenecek)
GENERATOR_CONFIG = {
    "start_date": "2016-01-01",
    "end_date": "2016-12-31 23:30:00",
    "time_interval": "30min",
    "customer_count": 150,
    "customer_id_prefix": "AUS_CUSTOMER_",
    "base_load": 35,
    "random_noise_std": 5,
    "min_load": 10,
    "max_load": 90,
    "participation_rate": [0.3, 0.5]  # Her zaman aralÄ±ÄŸÄ±nda aktif mÃ¼ÅŸteri oranÄ±
}

# Logger oluÅŸtur
logger = get_logger(__name__)

def generate_full_year_data(spark):
    """
    GerÃ§ekÃ§i tam yÄ±l akÄ±llÄ± sayaÃ§ verisi Ã¼ret
    
    Args:
        spark: Spark session
        
    Returns:
        tuple: (DataFrame, record_count)
    """
    logger.info("ğŸ­ GERÃ‡EK DAÄILIMLI TAM YIL AKILLI SAYAÃ‡ VERÄ°SÄ° ÃœRETÄ°LÄ°YOR...")
    start_time = time.time()
    
    # Veri Ã¼retim parametrelerini al (config.py'dan)
    start_date = GENERATOR_CONFIG["start_date"]
    end_date = GENERATOR_CONFIG["end_date"]
    time_interval = GENERATOR_CONFIG["time_interval"]
    customer_count = GENERATOR_CONFIG["customer_count"]
    customer_prefix = GENERATOR_CONFIG["customer_id_prefix"]
    
    # Tarih aralÄ±ÄŸÄ± ve mÃ¼ÅŸteri listesi oluÅŸtur
    dates = pd.date_range(start=start_date, end=end_date, freq=time_interval)
    customers = [f"{customer_prefix}{i:04d}" for i in range(1, customer_count + 1)]
    
    logger.info(f"ğŸ“… Ãœretiliyor: {len(dates):,} zaman damgasÄ± Ã— {len(customers)} mÃ¼ÅŸteri")
    logger.info(f"â±ï¸  Beklenen kayÄ±t: ~{len(dates) * len(customers) * 0.3:,.0f} (her zaman damgasÄ± iÃ§in %30 katÄ±lÄ±m)")
    
    data = []
    
    for i, timestamp in enumerate(dates):
        # Her zaman damgasÄ±: 30-50 rastgele mÃ¼ÅŸteri (gerÃ§ekÃ§i katÄ±lÄ±m)
        min_rate, max_rate = GENERATOR_CONFIG["participation_rate"]
        num_active = np.random.randint(int(len(customers) * min_rate), int(len(customers) * max_rate) + 1)
        active_customers = np.random.choice(customers, size=num_active, replace=False)
        
        for customer in active_customers:
            # GerÃ§ekÃ§i yÃ¼k Ã¶rÃ¼ntÃ¼leri
            hour = timestamp.hour
            month = timestamp.month
            day_of_week = timestamp.weekday()
            
            # Taban tÃ¼ketim
            base_load = GENERATOR_CONFIG["base_load"]
            
            # Mevsimsel Ã¶rÃ¼ntÃ¼ler (kWh benzeri Ã¶lÃ§ekleme)
            if month in [12, 1, 2]:  # KÄ±ÅŸ
                seasonal = 1.4
            elif month in [6, 7, 8]:  # Yaz  
                seasonal = 1.3
            else:  # Ä°lkbahar/Sonbahar
                seasonal = 0.9
            
            # GÃ¼nlÃ¼k Ã¶rÃ¼ntÃ¼ler
            if 6 <= hour <= 9 or 17 <= hour <= 22:  # Pik saatler
                daily = 1.5
            elif 23 <= hour or hour <= 5:  # Gece
                daily = 0.5
            else:  # Pik olmayan
                daily = 1.0
            
            # Hafta sonu vs hafta iÃ§i
            weekend_factor = 0.85 if day_of_week >= 5 else 1.0
            
            # Rastgele varyasyon
            noise = np.random.normal(0, GENERATOR_CONFIG["random_noise_std"])
            
            # Son yÃ¼k hesaplamasÄ±
            load = base_load * seasonal * daily * weekend_factor + noise
            load = max(GENERATOR_CONFIG["min_load"], min(GENERATOR_CONFIG["max_load"], load))  # GerÃ§ekÃ§i sÄ±nÄ±rlar
            
            data.append({
                'customer_id': str(customer),  # â† AÃ§Ä±k string dÃ¶nÃ¼ÅŸÃ¼mÃ¼
                'full_timestamp': timestamp,
                'load_percentage': float(load)  # â† AÃ§Ä±k float dÃ¶nÃ¼ÅŸÃ¼mÃ¼
            })
        
        # Ä°lerleme takibi
        if i % 5000 == 0 or i == len(dates) - 1:
            logger.info(f"   {i:,}/{len(dates):,} zaman damgasÄ± Ã¼retildi ({i/len(dates)*100:.1f}%)")
    
    # Spark DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r
    logger.info(f"ğŸ“Š {len(data):,} kayÄ±t Spark DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
    pandas_df = pd.DataFrame(data)
    
    # âœ… AÃ§Ä±k tip dÃ¶nÃ¼ÅŸÃ¼mÃ¼
    pandas_df['customer_id'] = pandas_df['customer_id'].astype(str)
    pandas_df['load_percentage'] = pandas_df['load_percentage'].astype(float)
    pandas_df['full_timestamp'] = pd.to_datetime(pandas_df['full_timestamp'])
    
    # AÃ§Ä±k ÅŸema ile Spark DataFrame oluÅŸtur
    schema = StructType([
        StructField("customer_id", StringType(), True),
        StructField("full_timestamp", TimestampType(), True),
        StructField("load_percentage", DoubleType(), True)
    ])
    
    spark_df = spark.createDataFrame(pandas_df, schema=schema)
    
    # Ã–nbelleÄŸe al
    spark_df.cache()
    
    # SonuÃ§ istatistikleri
    generation_time = time.time() - start_time
    final_count = spark_df.count()
    
    logger.info(f"âœ… TAM YIL VERÄ°SÄ° ÃœRETÄ°LDÄ°!")
    logger.info(f"ğŸ“Š Toplam kayÄ±t: {final_count:,}")
    logger.info(f"â±ï¸  Ãœretim sÃ¼resi: {generation_time:.1f}s")
    logger.info(f"ğŸ“ˆ Ãœretim hÄ±zÄ±: {final_count/generation_time:,.0f} kayÄ±t/saniye")
    
    # Ã–rnek gÃ¶ster
    logger.info("ğŸ“‹ Ã–rnek veri:")
    spark_df.show(5, truncate=False)
    
    # Tarih aralÄ±ÄŸÄ± gÃ¶ster
    from pyspark.sql.functions import min as spark_min, max as spark_max
    date_stats = spark_df.select(
        spark_min("full_timestamp").alias("start_date"),
        spark_max("full_timestamp").alias("end_date")
    ).collect()[0]
    
    logger.info(f"ğŸ“… Tarih aralÄ±ÄŸÄ±: {date_stats['start_date']} - {date_stats['end_date']}")
    
    return spark_df, final_count