#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Makine Ã–ÄŸrenimi Pipeline ModÃ¼lÃ¼

Bu modÃ¼l, ML pipeline oluÅŸturma, eÄŸitme ve deÄŸerlendirme iÅŸlevlerini saÄŸlar.
"""

import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pyspark.ml import Pipeline
from pyspark.ml.feature import VectorAssembler, StandardScaler
from pyspark.ml.regression import GBTRegressor
from pyspark.ml.evaluation import RegressionEvaluator

from utils.logger import get_logger
from utils.config import MODEL_CONFIG
from utils.mlflow_utils import save_model_predictions_to_db

# Logger oluÅŸtur
logger = get_logger(__name__)

def create_ml_pipeline(feature_columns):
    """
    Ã–zellik Ã¶lÃ§eklendirme ve GBT regresyonu ile ML pipeline oluÅŸtur
    
    Args:
        feature_columns: Ã–zellik kolonu isimleri
        
    Returns:
        Pipeline: OluÅŸturulan ML pipeline
    """
    logger.info("ğŸ¤– ML PIPELINE OLUÅTURULUYOR...")
    
    # Hiperparametreleri yapÄ±landÄ±rmadan al
    max_depth = MODEL_CONFIG.get("max_depth", 6)
    max_bins = MODEL_CONFIG.get("max_bins", 32)
    max_iter = MODEL_CONFIG.get("max_iter", 100)
    step_size = MODEL_CONFIG.get("step_size", 0.1)
    subsampling_rate = MODEL_CONFIG.get("subsampling_rate", 0.8)
    feature_subset_strategy = MODEL_CONFIG.get("feature_subset_strategy", "sqrt")
    seed = MODEL_CONFIG.get("seed", 42)
    
    # VektÃ¶r dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼
    logger.info(f"ğŸ”¢ Ã–zellik vektÃ¶rleri oluÅŸturuluyor ({len(feature_columns)} Ã¶zellik)")
    assembler = VectorAssembler(
        inputCols=feature_columns,
        outputCol="raw_features"
    )
    
    # Ã–zellik Ã¶lÃ§eklendirici
    logger.info("ğŸ“ Ã–zellik Ã¶lÃ§eklendirme tanÄ±mlanÄ±yor (StandardScaler)")
    scaler = StandardScaler(
        inputCol="raw_features",
        outputCol="scaled_features",
        withStd=True,
        withMean=True
    )
    
    # GBT Regresyonu
    logger.info(f"ğŸŒ³ GBT Regresyonu tanÄ±mlanÄ±yor (max_depth={max_depth}, max_iter={max_iter})")
    gbt = GBTRegressor(
        featuresCol="scaled_features",
        labelCol="total_daily_energy",
        predictionCol="prediction",
        maxDepth=max_depth,
        maxBins=max_bins,
        maxIter=max_iter,
        stepSize=step_size,
        subsamplingRate=subsampling_rate,
        featureSubsetStrategy=feature_subset_strategy,
        seed=seed
    )
    
    # Pipeline oluÅŸtur
    pipeline = Pipeline(stages=[assembler, scaler, gbt])
    
    logger.info(f"âœ… Pipeline oluÅŸturuldu ({len(feature_columns)} Ã¶zellik)")
    logger.info(f"ğŸ¯ Hedef: total_daily_energy")
    logger.info(f"ğŸŒ³ Algoritma: Gradient Boosted Trees")
    logger.info(f"âš™ï¸ Hiperparametreler: max_depth={max_depth}, max_iter={max_iter}, step_size={step_size}")
    
    return pipeline

def train_and_evaluate_model(pipeline, train_df, val_df, test_df):
    """
    Modeli eÄŸit ve performansÄ±nÄ± deÄŸerlendir
    
    Args:
        pipeline: ML pipeline
        train_df: EÄŸitim DataFrame'i
        val_df: DoÄŸrulama DataFrame'i
        test_df: Test DataFrame'i
        
    Returns:
        tuple: (model, metrics, test_predictions)
    """
    logger.info("ğŸš€ MODEL EÄÄ°TÄ°LÄ°YOR...")
    train_start = time.time()
    
    # Pipeline'Ä± eÄŸit
    model = pipeline.fit(train_df)
    
    training_time = time.time() - train_start
    logger.info(f"âœ… EÄŸitim {training_time:.1f}s sÃ¼rede tamamlandÄ±")
    
    # Tahminler yap
    logger.info("ğŸ“Š MODEL DEÄERLENDÄ°RÄ°LÄ°YOR...")
    
    train_predictions = model.transform(train_df)
    val_predictions = model.transform(val_df)
    test_predictions = model.transform(test_df)
    
    # DeÄŸerlendirici
    evaluator = RegressionEvaluator(
        labelCol="total_daily_energy",
        predictionCol="prediction"
    )
    
    # Metrikleri hesapla
    def calculate_metrics(predictions_df, dataset_name):
        r2 = evaluator.evaluate(predictions_df, {evaluator.metricName: "r2"})
        rmse = evaluator.evaluate(predictions_df, {evaluator.metricName: "rmse"})
        mae = evaluator.evaluate(predictions_df, {evaluator.metricName: "mae"})
        
        # GerÃ§ek ve tahmin deÄŸerlerini topla
        pd_df = predictions_df.select("date", "total_daily_energy", "prediction").toPandas()
        
        # Ek metrikler hesapla
        mape = np.mean(np.abs((pd_df["total_daily_energy"] - pd_df["prediction"]) / pd_df["total_daily_energy"])) * 100
        
        # Maksimum hata
        max_error = np.max(np.abs(pd_df["total_daily_energy"] - pd_df["prediction"]))
        max_error_date = pd_df.loc[np.abs(pd_df["total_daily_energy"] - pd_df["prediction"]).idxmax(), "date"]
        
        return {
            f"{dataset_name}_r2": r2,
            f"{dataset_name}_rmse": rmse,
            f"{dataset_name}_mae": mae,
            f"{dataset_name}_mape": mape,
            f"{dataset_name}_max_error": max_error,
            f"{dataset_name}_max_error_date": max_error_date
        }
    
    # TÃ¼m setler iÃ§in metrikleri al
    train_metrics = calculate_metrics(train_predictions, "train")
    val_metrics = calculate_metrics(val_predictions, "val")
    test_metrics = calculate_metrics(test_predictions, "test")
    
    # TÃ¼m metrikleri birleÅŸtir
    all_metrics = {**train_metrics, **val_metrics, **test_metrics, "training_time": training_time}
    
    # SonuÃ§larÄ± gÃ¶ster
    logger.info(f"ğŸ¯ MODEL PERFORMANSI:")
    logger.info(f"   ğŸ“š EÄŸitim  RÂ²: {train_metrics['train_r2']:.4f} | RMSE: {train_metrics['train_rmse']:.2f} | MAE: {train_metrics['train_mae']:.2f} | MAPE: {train_metrics['train_mape']:.2f}%")
    logger.info(f"   ğŸ” DoÄŸrulama RÂ²: {val_metrics['val_r2']:.4f} | RMSE: {val_metrics['val_rmse']:.2f} | MAE: {val_metrics['val_mae']:.2f} | MAPE: {val_metrics['val_mape']:.2f}%")
    logger.info(f"   ğŸ§ª Test   RÂ²: {test_metrics['test_r2']:.4f} | RMSE: {test_metrics['test_rmse']:.2f} | MAE: {test_metrics['test_mae']:.2f} | MAPE: {test_metrics['test_mape']:.2f}%")
    
    # AÅŸÄ±rÄ± Ã¶ÄŸrenme analizi
    train_test_gap = train_metrics['train_r2'] - test_metrics['test_r2']
    logger.info(f"   ğŸ”¬ AÅŸÄ±rÄ± Ã–ÄŸrenme BoÅŸluÄŸu: {train_test_gap:.4f}")
    
    if train_test_gap > 0.1:
        logger.warning("   âš ï¸  Model aÅŸÄ±rÄ± Ã¶ÄŸrenme gÃ¶steriyor olabilir")
    else:
        logger.info("   âœ… Ä°yi genelleme")
    
    # Tahmin gÃ¶rselleÅŸtirmesi oluÅŸtur
    try:
        create_prediction_plot(test_predictions, "test_predictions.png")
        logger.info("ğŸ“Š Test tahminleri grafiÄŸi oluÅŸturuldu: test_predictions.png")
    except Exception as e:
        logger.warning(f"âš ï¸ Tahmin grafiÄŸi oluÅŸturulamadÄ±: {e}")
    
    # Tahminleri veritabanÄ±na kaydetmeyi dene
    try:
        # MLflow run_id al (aktif Ã§alÄ±ÅŸma varsa)
        import mlflow
        run_id = mlflow.active_run().info.run_id if mlflow.active_run() else None
        
        if run_id:
            # VeritabanÄ±na kaydet
            save_model_predictions_to_db(test_predictions, run_id)
        else:
            logger.warning("âš ï¸ MLflow Ã§alÄ±ÅŸmasÄ± bulunamadÄ±, tahminler veritabanÄ±na kaydedilemiyor")
    except Exception as e:
        logger.warning(f"âš ï¸ Tahminlerin veritabanÄ±na kaydedilmesi baÅŸarÄ±sÄ±z: {e}")
    
    return model, all_metrics, test_predictions

def create_prediction_plot(predictions_df, filename=None):
    """
    Tahmin-gerÃ§ek deÄŸer karÅŸÄ±laÅŸtÄ±rma grafiÄŸi oluÅŸtur
    
    Args:
        predictions_df: Tahmin iÃ§eren DataFrame
        filename: Kaydedilecek dosya adÄ± (None ise kaydetmez)
    """
    # Pandas DataFrame'ine dÃ¶nÃ¼ÅŸtÃ¼r
    pdf = predictions_df.select("date", "total_daily_energy", "prediction").toPandas()
    
    # Tarihe gÃ¶re sÄ±rala
    pdf["date"] = pd.to_datetime(pdf["date"])
    pdf = pdf.sort_values("date")
    
    # GrafiÄŸi oluÅŸtur
    plt.figure(figsize=(12, 6))
    
    # GerÃ§ek deÄŸerler
    plt.plot(pdf["date"], pdf["total_daily_energy"], 'b-', label='GerÃ§ek DeÄŸer', linewidth=2)
    
    # Tahminler
    plt.plot(pdf["date"], pdf["prediction"], 'r--', label='Tahmin', linewidth=2)
    
    # Hata alanÄ±
    plt.fill_between(pdf["date"], 
                    pdf["total_daily_energy"], 
                    pdf["prediction"], 
                    color='gray', alpha=0.3, label='Hata')
    
    # Grafik biÃ§imlendirme
    plt.title('Toplam GÃ¼nlÃ¼k Enerji: GerÃ§ek vs Tahmin')
    plt.xlabel('Tarih')
    plt.ylabel('Enerji')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    # Dosyaya kaydet
    if filename:
        plt.savefig(filename, dpi=300, bbox_inches='tight')
    
    plt.close()