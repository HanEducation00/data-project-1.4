#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Spark YardÄ±mcÄ± FonksiyonlarÄ±

Bu modÃ¼l Spark session yÃ¶netimi ve veri iÅŸleme yardÄ±mcÄ± fonksiyonlarÄ±nÄ± iÃ§erir.
Mevcut iÅŸlevselliÄŸi korurken, yeni yapÄ±landÄ±rma ve loglama sistemiyle entegre eder.
"""

from pyspark.sql import SparkSession

from utils.logger import get_logger
from utils.config import SPARK_CONFIG
from utils.connections import get_spark_session

# Logger oluÅŸtur
logger = get_logger(__name__)

def create_spark_session():
    """
    Spark session oluÅŸtur
    
    Returns:
        SparkSession: YapÄ±landÄ±rÄ±lmÄ±ÅŸ Spark session
    """
    logger.info("âš¡ SPARK SESSION OLUÅTURULUYOR...")
    
    # Mevcut baÄŸlantÄ± fonksiyonunu kullan
    spark = get_spark_session()
    
    logger.info(f"âœ… Spark session baÅŸarÄ±yla oluÅŸturuldu: {spark.version}")
    return spark

def cache_dataframe(df, name="DataFrame"):
    """
    DataFrame'i Ã¶nbelleÄŸe al ve istatistiklerini gÃ¶ster
    
    Args:
        df: Spark DataFrame
        name: DataFrame adÄ± (loglama iÃ§in)
        
    Returns:
        DataFrame: Ã–nbelleÄŸe alÄ±nmÄ±ÅŸ DataFrame
    """
    logger.info(f"ğŸ’¾ {name} Ã¶nbelleÄŸe alÄ±nÄ±yor...")
    
    try:
        # DataFrame'i Ã¶nbelleÄŸe al
        df.cache()
        
        # Ä°statistikler
        count = df.count()
        columns = len(df.columns)
        partitions = df.rdd.getNumPartitions()
        
        logger.info(f"âœ… {name} Ã¶nbelleÄŸe alÄ±ndÄ±: {count:,} satÄ±r, {columns} kolon, {partitions} partition")
        return df
        
    except Exception as e:
        logger.error(f"âŒ {name} Ã¶nbelleÄŸe alÄ±nÄ±rken hata: {e}")
        return df

def show_dataframe_info(df, name="DataFrame", sample_rows=5):
    """
    DataFrame hakkÄ±nda bilgi gÃ¶ster
    
    Args:
        df: Spark DataFrame
        name: DataFrame adÄ±
        sample_rows: GÃ¶sterilecek Ã¶rnek satÄ±r sayÄ±sÄ±
    """
    logger.info(f"ğŸ“Š {name.upper()} BÄ°LGÄ°LERÄ°:")
    
    try:
        # Temel bilgiler
        count = df.count()
        columns = df.columns
        
        logger.info(f"ğŸ“ Toplam kayÄ±t: {count:,}")
        logger.info(f"ğŸ§© Kolonlar: {len(columns)}")
        
        # Ã–rnek veri
        logger.info(f"ğŸ“‹ Ã–rnek veriler:")
        df.show(sample_rows, truncate=False)
        
    except Exception as e:
        logger.error(f"âŒ DataFrame bilgisi gÃ¶sterilirken hata: {e}")

def unpersist_dataframe(df, name="DataFrame"):
    """
    DataFrame'i Ã¶nbellekten Ã§Ä±kar
    
    Args:
        df: Spark DataFrame
        name: DataFrame adÄ± (loglama iÃ§in)
        
    Returns:
        DataFrame: Ã–nbellekten Ã§Ä±karÄ±lmÄ±ÅŸ DataFrame
    """
    logger.info(f"ğŸ§¹ {name} Ã¶nbellekten Ã§Ä±karÄ±lÄ±yor...")
    
    try:
        df.unpersist()
        logger.info(f"âœ… {name} Ã¶nbellekten Ã§Ä±karÄ±ldÄ±")
        return df
    except Exception as e:
        logger.error(f"âŒ {name} Ã¶nbellekten Ã§Ä±karÄ±lÄ±rken hata: {e}")
        return df