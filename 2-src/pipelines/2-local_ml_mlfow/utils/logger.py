#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Loglama YÃ¶neticisi

Bu modÃ¼l, ML pipeline'Ä±n Ã§alÄ±ÅŸmasÄ± sÄ±rasÄ±nda neler olduÄŸunu kaydetmek,
hatalarÄ± izlemek ve iÅŸlem durumunu takip etmek iÃ§in kullanÄ±lÄ±r.
"""

import logging
import os
from datetime import datetime

# Log seviyesi mapping
LOG_LEVELS = {
    'DEBUG': logging.DEBUG,
    'INFO': logging.INFO,
    'WARNING': logging.WARNING,
    'ERROR': logging.ERROR,
    'CRITICAL': logging.CRITICAL
}

class MLPipelineLogger:
    """ML Pipeline iÃ§in Ã¶zel logger sÄ±nÄ±fÄ±"""
    
    def __init__(self, name, log_level='INFO', log_to_file=True, log_dir='/workspace/logs'):
        self.name = name
        self.log_level = LOG_LEVELS.get(log_level.upper(), logging.INFO)
        self.log_to_file = log_to_file
        self.log_dir = log_dir
        self.logger = None
        self._setup_logger()
    
    def _setup_logger(self):
        """Logger'Ä± yapÄ±landÄ±r"""
        # Logger oluÅŸtur
        self.logger = logging.getLogger(self.name)
        self.logger.setLevel(self.log_level)
        
        # EÄŸer handler'lar zaten varsa, tekrar ekleme
        if self.logger.handlers:
            return
        
        # Formatter oluÅŸtur (emoji desteÄŸi ile)
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        # Console handler
        console_handler = logging.StreamHandler()
        console_handler.setLevel(self.log_level)
        console_handler.setFormatter(formatter)
        self.logger.addHandler(console_handler)
        
        # File handler (opsiyonel)
        if self.log_to_file:
            self._add_file_handler(formatter)
    
    def _add_file_handler(self, formatter):
        """Dosya handler'Ä± ekle"""
        try:
            # Log dizinini oluÅŸtur
            os.makedirs(self.log_dir, exist_ok=True)
            
            # Log dosya adÄ±
            today = datetime.now().strftime('%Y-%m-%d')
            log_filename = f"ml_pipeline_{today}.log"
            log_filepath = os.path.join(self.log_dir, log_filename)
            
            # File handler
            file_handler = logging.FileHandler(log_filepath, encoding='utf-8')
            file_handler.setLevel(self.log_level)
            file_handler.setFormatter(formatter)
            self.logger.addHandler(file_handler)
            
            self.info(f"ğŸ“„ Log dosyasÄ±: {log_filepath}")
            
        except Exception as e:
            self.warning(f"âš ï¸ Log dosyasÄ± oluÅŸturulamadÄ±: {e}")
    
    def debug(self, message):
        """Debug seviyesi log"""
        self.logger.debug(message)
    
    def info(self, message):
        """Info seviyesi log"""
        self.logger.info(message)
    
    def warning(self, message):
        """Warning seviyesi log"""
        self.logger.warning(message)
    
    def error(self, message):
        """Error seviyesi log"""
        self.logger.error(message)
    
    def critical(self, message):
        """Critical seviyesi log"""
        self.logger.critical(message)
    
    def log_dataframe_info(self, df, name="DataFrame"):
        """DataFrame hakkÄ±nda bilgi logla"""
        try:
            count = df.count()
            columns = df.columns
            self.info(f"ğŸ“Š {name}: {count:,} kayÄ±t, {len(columns)} kolon")
            self.debug(f"ğŸ” {name} kolonlarÄ±: {columns}")
        except Exception as e:
            self.error(f"âŒ {name} bilgisi alÄ±namadÄ±: {e}")
    
    def log_feature_info(self, feature_columns, importance_dict=None):
        """Ã–zellik bilgilerini logla"""
        try:
            self.info(f"ğŸ§© Toplam Ã¶zellik sayÄ±sÄ±: {len(feature_columns)}")
            
            # En Ã¶nemli Ã¶zellikleri logla
            if importance_dict and len(importance_dict) > 0:
                sorted_features = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)
                self.info("ğŸ” En Ã¶nemli 5 Ã¶zellik:")
                for i, (feature, score) in enumerate(sorted_features[:5], 1):
                    self.info(f"   {i}. {feature} = {score:.4f}")
        except Exception as e:
            self.error(f"âŒ Ã–zellik bilgisi loglama hatasÄ±: {e}")
    
    def log_model_metrics(self, metrics):
        """Model metriklerini logla"""
        try:
            self.info("ğŸ“ MODEL METRÄ°KLERÄ°:")
            
            # EÄŸitim metrikleri
            if "train_r2" in metrics:
                self.info(f"ğŸ“š EÄŸitim: RÂ² = {metrics['train_r2']:.4f}, RMSE = {metrics['train_rmse']:.2f}, MAE = {metrics['train_mae']:.2f}")
            
            # DoÄŸrulama metrikleri
            if "val_r2" in metrics:
                self.info(f"ğŸ” DoÄŸrulama: RÂ² = {metrics['val_r2']:.4f}, RMSE = {metrics['val_rmse']:.2f}, MAE = {metrics['val_mae']:.2f}")
            
            # Test metrikleri
            if "test_r2" in metrics:
                self.info(f"ğŸ§ª Test: RÂ² = {metrics['test_r2']:.4f}, RMSE = {metrics['test_rmse']:.2f}, MAE = {metrics['test_mae']:.2f}")
                
            # EÄŸitim sÃ¼resi
            if "training_time" in metrics:
                self.info(f"â±ï¸ EÄŸitim sÃ¼resi: {metrics['training_time']:.1f}s")
        except Exception as e:
            self.error(f"âŒ Model metrikleri loglama hatasÄ±: {e}")
    
    def log_mlflow_info(self, run_id, experiment_name):
        """MLflow bilgilerini logla"""
        self.info(f"ğŸš€ MLflow Run ID: {run_id}")
        self.info(f"ğŸ§ª MLflow Deney: {experiment_name}")
        self.info(f"ğŸ”— MLflow UI: http://mlflow-server:5000")
    
    def log_processing_start(self, operation_name):
        """Ä°ÅŸlem baÅŸlangÄ±cÄ±nÄ± logla"""
        self.info(f"ğŸš€ === {operation_name} BAÅLADI ===")
    
    def log_processing_end(self, operation_name, duration_seconds=None):
        """Ä°ÅŸlem sonunu logla"""
        if duration_seconds:
            self.info(f"âœ… === {operation_name} TAMAMLANDI ({duration_seconds:.2f}s) ===")
        else:
            self.info(f"âœ… === {operation_name} TAMAMLANDI ===")
    
    def log_error_with_details(self, error, context=""):
        """DetaylÄ± hata logu"""
        import traceback
        error_details = traceback.format_exc()
        self.error(f"âŒ HATA {context}: {str(error)}")
        self.debug(f"Hata detaylarÄ±:\n{error_details}")
    
    def log_config_info(self, config_dict, config_name="KonfigÃ¼rasyon"):
        """KonfigÃ¼rasyon bilgilerini logla"""
        self.info(f"âš™ï¸ {config_name} yÃ¼klendi:")
        for key, value in config_dict.items():
            # Åifre alanlarÄ±nÄ± gizle
            if 'password' in key.lower() or 'pass' in key.lower():
                self.info(f"  {key}: ***")
            else:
                self.info(f"  {key}: {value}")

# Global logger instance'larÄ±
_loggers = {}

def get_logger(name, log_level='INFO', log_to_file=True):
    """
    Logger instance'Ä± getir (singleton pattern)
    
    Args:
        name (str): Logger adÄ±
        log_level (str): Log seviyesi
        log_to_file (bool): Dosyaya log yazÄ±lsÄ±n mÄ±
        
    Returns:
        MLPipelineLogger: Logger instance'Ä±
    """
    if name not in _loggers:
        _loggers[name] = MLPipelineLogger(name, log_level, log_to_file)
    
    return _loggers[name]

def set_global_log_level(log_level):
    """TÃ¼m logger'larÄ±n log seviyesini deÄŸiÅŸtir"""
    level = LOG_LEVELS.get(log_level.upper(), logging.INFO)
    
    for logger in _loggers.values():
        logger.logger.setLevel(level)
        for handler in logger.logger.handlers:
            handler.setLevel(level)

def log_pipeline_start():
    """Pipeline baÅŸlangÄ±cÄ±nÄ± logla"""
    logger = get_logger('PIPELINE')
    logger.info("=" * 60)
    logger.info("ğŸš€ ENERGY FORECASTING ML PIPELINE BAÅLADI")
    logger.info(f"â±ï¸ Zaman: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 60)

def log_pipeline_end():
    """Pipeline sonunu logla"""
    logger = get_logger('PIPELINE')
    logger.info("=" * 60)
    logger.info("âœ… ENERGY FORECASTING ML PIPELINE TAMAMLANDI")
    logger.info(f"â±ï¸ Zaman: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 60)