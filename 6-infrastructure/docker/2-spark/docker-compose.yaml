# Spark Cluster - Dynamic Port Configuration
services:
  spark-master:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: ${ENVIRONMENT:-development}-spark-master
    hostname: spark-master
    ports:
      - "${SPARK_MASTER_WEBUI_PORT:-8080}:8080"        # ← DİNAMİK!
      - "${SPARK_MASTER_CLUSTER_PORT:-7077}:7077"      # ← DİNAMİK!
    networks:
      data-platform:
        ipv4_address: ${SPARK_IP_BASE}.10
    volumes:
      - spark-data:/opt/spark/data
      - ./spark/spark-master.sh:/spark-master.sh
      - ../../../2-src:/workspace
      - ../../../models:/models
      - ../../../4-integration-tests:/integration-tests
    command: /spark-master.sh
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    healthcheck:
      test: ["CMD", "curl", "-f", "http://spark-master:8080"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  spark-worker-1:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: ${ENVIRONMENT:-development}-spark-worker-1
    hostname: spark-worker-1
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - "${SPARK_WORKER_1_PORT:-8081}:8081"            # ← DİNAMİK!
    networks:
      data-platform:
        ipv4_address: ${SPARK_IP_BASE}.11
    volumes:
      - spark-data:/opt/spark/data
      - ./spark/spark-worker.sh:/spark-worker.sh
      - ../../../2-src:/workspace
      - ../../../models:/models
      - ../../../4-integration-tests:/integration-tests
    command: /spark-worker.sh
    environment:
      - SPARK_LOCAL_IP=spark-worker-1
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1g
      - SPARK_WORKER_PORT=${SPARK_WORKER_1_INTERNAL_PORT:-7078}    # ← DİNAMİK!
      - SPARK_WORKER_WEBUI_PORT=8081

  spark-worker-2:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: ${ENVIRONMENT:-development}-spark-worker-2
    hostname: spark-worker-2
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - "${SPARK_WORKER_2_PORT:-8082}:8081"            # ← DİNAMİK!
    networks:
      data-platform:
        ipv4_address: ${SPARK_IP_BASE}.12
    volumes:
      - spark-data:/opt/spark/data
      - ./spark/spark-worker.sh:/spark-worker.sh
      - ../../../2-src:/workspace
      - ../../../models:/models
      - ../../../4-integration-tests:/integration-tests
    command: /spark-worker.sh
    environment:
      - SPARK_LOCAL_IP=spark-worker-2
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1g
      - SPARK_WORKER_PORT=${SPARK_WORKER_2_INTERNAL_PORT:-7079}    # ← DİNAMİK!
      - SPARK_WORKER_WEBUI_PORT=8081

  spark-worker-3:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: ${ENVIRONMENT:-development}-spark-worker-3
    hostname: spark-worker-3
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - "${SPARK_WORKER_3_PORT:-8083}:8081"            # ← DİNAMİK!
    networks:
      data-platform:
        ipv4_address: ${SPARK_IP_BASE}.13
    volumes:
      - spark-data:/opt/spark/data
      - ./spark/spark-worker.sh:/spark-worker.sh
      - ../../../2-src:/workspace
      - ../../../models:/models
      - ../../../4-integration-tests:/integration-tests
    command: /spark-worker.sh
    environment:
      - SPARK_LOCAL_IP=spark-worker-3
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1g
      - SPARK_WORKER_PORT=${SPARK_WORKER_3_INTERNAL_PORT:-7080}    # ← DİNAMİK!
      - SPARK_WORKER_WEBUI_PORT=8081

  spark-client:
    build:
      context: ./spark-client
      dockerfile: Dockerfile
    container_name: ${ENVIRONMENT:-development}-spark-client
    hostname: spark-client
    depends_on:
      spark-master:
        condition: service_healthy
    networks:
      data-platform:
        ipv4_address: ${SPARK_IP_BASE}.20
    volumes:
      - ../../../2-src:/workspace
      - ../../../models:/models
      - ../../../4-integration-tests:/integration-tests
      - /home/han/data:/data
    environment:
      - SPARK_LOCAL_IP=spark-client
      - SPARK_MASTER=spark://spark-master:7077
      - PYTHONPATH=/workspace
    working_dir: /workspace
    tty: true
    stdin_open: true
    command: >
      bash -c "
        echo 'Spark Client ready!'
        echo 'Workspace: /workspace'
        echo 'Source code: /workspace (from 2-src/)'
        echo 'Models: /models'
        echo 'Integration Tests: /integration-tests'
        ls -la /workspace
        tail -f /dev/null
      "